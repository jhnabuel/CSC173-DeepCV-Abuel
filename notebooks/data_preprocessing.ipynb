{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17bf8da",
   "metadata": {},
   "source": [
    "# Deep Learning for Tuberculosis Detection and Classification: A YOLO-v8 + Convolutional Block Attention Module Approach\n",
    "\n",
    "By: John Abuel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c6cad5",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe59ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9fad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Input Paths\n",
    "    RAW_IMAGES = \"../dataset/raw_data/TBX11K/imgs\" \n",
    "    ANNOTATION_FILE = \"../dataset/raw_data/TBX11K/annotations/json/TBX11K_train.json\"\n",
    "    \n",
    "    # Output Paths\n",
    "    OUTPUT_BASE = \"../dataset/yolo_ready\"\n",
    "    TRAIN_IMAGES = os.path.join(OUTPUT_BASE, \"images/train\")\n",
    "    VAL_IMAGES = os.path.join(OUTPUT_BASE, \"images/val\")\n",
    "    TEST_IMAGES = os.path.join(OUTPUT_BASE, \"images/test\")\n",
    "    TRAIN_LABELS = os.path.join(OUTPUT_BASE, \"labels/train\")\n",
    "    VAL_LABELS = os.path.join(OUTPUT_BASE, \"labels/val\")\n",
    "    TEST_LABELS = os.path.join(OUTPUT_BASE, \"labels/test\")\n",
    "\n",
    "    # Parameters\n",
    "    MIN_BOX_AREA = 50       # Filter tiny noise boxes\n",
    "    TRAIN_RATIO = 0.8\n",
    "    VAL_RATIO = 0.2         # (Test will take the remainder if any, or 0)\n",
    "    TARGET_SIZE = (512, 512) # Resize for YOLOv8\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898f158",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0ba6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(json_path):\n",
    "    print(f\"Loading annotations from {json_path}...\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    images = {}\n",
    "    for img in data['images']:\n",
    "        images[img['id']] = img\n",
    "        images[img['id']]['annotations'] = []\n",
    "        \n",
    "    for ann in data['annotations']:\n",
    "        if ann['image_id'] in images:\n",
    "            # Map Category Name for convenience\n",
    "            cat_id = ann['category_id']\n",
    "            # TBX11K IDs: 1=Active, 2=Latent, 3=Uncertain\n",
    "            if cat_id == 1: name = 'ActiveTuberculosis'\n",
    "            elif cat_id == 2: name = 'ObsoletePulmonaryTuberculosis'\n",
    "            else: name = 'Uncertain'\n",
    "            \n",
    "            ann['category_name'] = name\n",
    "            images[ann['image_id']]['annotations'].append(ann)\n",
    "            \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0043d11",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85fb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(images_data, config):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA CLEANING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cleaned_data = {}\n",
    "    removed_count = 0\n",
    "    \n",
    "    for img_id, img_info in images_data.items():\n",
    "        src_path = os.path.join(config.RAW_IMAGES, img_info['file_name'])\n",
    "        \n",
    "        # 1. Check if file exists\n",
    "        if not os.path.exists(src_path):\n",
    "            removed_count += 1\n",
    "            continue\n",
    "\n",
    "        # 2. Filter Invalid Boxes\n",
    "        original_ann_count = len(img_info['annotations'])\n",
    "        valid_annotations = []\n",
    "        \n",
    "        for ann in img_info['annotations']:\n",
    "            bbox = ann['bbox'] # [x, y, w, h]\n",
    "            # Ensure box has positive area and meets threshold\n",
    "            if bbox[2] > 0 and bbox[3] > 0:\n",
    "                if (bbox[2] * bbox[3]) >= config.MIN_BOX_AREA:\n",
    "                    valid_annotations.append(ann)\n",
    "        \n",
    "        # 3. LOGIC FIX:\n",
    "        # If image HAD boxes (was TB), but we filtered them all out (too small),\n",
    "        # DROP the image. Do not label a TB patient as \"Healthy\" just because boxes were small.\n",
    "        if original_ann_count > 0 and len(valid_annotations) == 0:\n",
    "            removed_count += 1\n",
    "            continue \n",
    "\n",
    "        # If it was Healthy (0 boxes) or has valid boxes, keep it.\n",
    "        img_info['annotations'] = valid_annotations\n",
    "        cleaned_data[img_id] = img_info\n",
    "\n",
    "    print(f\"✓ Original dataset: {len(images_data)} images\")\n",
    "    print(f\"✓ Cleaned dataset: {len(cleaned_data)} images\")\n",
    "    print(f\"✓ Removed: {removed_count} images (missing files or invalid boxes)\")\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32898948",
   "metadata": {},
   "source": [
    "## Split the dataset for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3e64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(images_data, config):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATASET SPLITTING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Separate images with and without TB\n",
    "    with_tb = []\n",
    "    without_tb = []\n",
    "    \n",
    "    for img_id, img_info in images_data.items():\n",
    "        if len(img_info['annotations']) > 0:\n",
    "            with_tb.append(img_info)\n",
    "        else:\n",
    "            without_tb.append(img_info)\n",
    "            \n",
    "    # Shuffle\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(with_tb)\n",
    "    np.random.shuffle(without_tb)\n",
    "    \n",
    "    # Calculate Split Indices\n",
    "    def get_split_indices(data_list):\n",
    "        n = len(data_list)\n",
    "        train_end = int(n * config.TRAIN_RATIO)\n",
    "        # If val ratio fills the rest, test is empty (typical for this dataset structure)\n",
    "        return data_list[:train_end], data_list[train_end:]\n",
    "\n",
    "    train_tb, val_tb = get_split_indices(with_tb)\n",
    "    train_no_tb, val_no_tb = get_split_indices(without_tb)\n",
    "    \n",
    "    # Combine\n",
    "    splits = {\n",
    "        'train': train_tb + train_no_tb,\n",
    "        'val': val_tb + val_no_tb,\n",
    "        'test': [] # Optional, can add back if needed\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ Train: {len(splits['train'])} images\")\n",
    "    print(f\"✓ Val:   {len(splits['val'])} images\")\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a99932d",
   "metadata": {},
   "source": [
    "## Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99cf4555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_id(category_name):\n",
    "    \"\"\"Map categories to YOLO IDs: Active=0, Latent=1\"\"\"\n",
    "    name = category_name.lower()\n",
    "    if 'active' in name: return 0\n",
    "    elif 'obsolete' in name or 'latent' in name: return 1\n",
    "    return -1 # Skip\n",
    "\n",
    "def convert_to_yolo_format(bbox, img_w, img_h):\n",
    "    # Convert COCO (x, y, w, h) to YOLO (cx, cy, w, h) normalized\n",
    "    x, y, w, h = bbox\n",
    "    cx = (x + w/2) / img_w\n",
    "    cy = (y + h/2) / img_h\n",
    "    nw = w / img_w\n",
    "    nh = h / img_h\n",
    "    return [max(0, min(1, val)) for val in [cx, cy, nw, nh]]\n",
    "\n",
    "def process_and_save_split(split_data, split_name, config):\n",
    "    print(f\"\\nProcessing {split_name} split...\")\n",
    "    \n",
    "    # Map split name to folders\n",
    "    if split_name == 'train':\n",
    "        img_dir, lbl_dir = config.TRAIN_IMAGES, config.TRAIN_LABELS\n",
    "    else:\n",
    "        img_dir, lbl_dir = config.VAL_IMAGES, config.VAL_LABELS\n",
    "        \n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    os.makedirs(lbl_dir, exist_ok=True)\n",
    "\n",
    "    for img_info in tqdm(split_data):\n",
    "        src_path = os.path.join(config.RAW_IMAGES, img_info['file_name'])\n",
    "        \n",
    "        # FIX 1: FLATTEN FILENAME\n",
    "        # Converts 'tb/tb001.png' -> 'tb001.png' to prevent subdirectory errors\n",
    "        flat_name = os.path.basename(img_info['file_name'])\n",
    "        dst_img_path = os.path.join(img_dir, flat_name)\n",
    "        \n",
    "        # Read Image\n",
    "        img = cv2.imread(src_path)\n",
    "        if img is None: continue\n",
    "        \n",
    "        h_orig, w_orig = img.shape[:2]\n",
    "        \n",
    "        # FIX 2: RESIZE\n",
    "        # Resize to 512x512 now to save massive space/time later\n",
    "        img_resized = cv2.resize(img, config.TARGET_SIZE)\n",
    "        cv2.imwrite(dst_img_path, img_resized)\n",
    "        \n",
    "        # Create Label File\n",
    "        txt_name = os.path.splitext(flat_name)[0] + \".txt\"\n",
    "        txt_path = os.path.join(lbl_dir, txt_name)\n",
    "        \n",
    "        with open(txt_path, 'w') as f:\n",
    "            for ann in img_info['annotations']:\n",
    "                # FIX 3: CLASS MAPPING\n",
    "                cls_id = get_class_id(ann['category_name'])\n",
    "                if cls_id == -1: continue # Skip uncertain TB\n",
    "                \n",
    "                # Convert coords using ORIGINAL dimensions\n",
    "                yolo_box = convert_to_yolo_format(ann['bbox'], w_orig, h_orig)\n",
    "                f.write(f\"{cls_id} {' '.join(map(str, yolo_box))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ea0f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations from ../dataset/raw_data/TBX11K/annotations/json/TBX11K_train.json...\n",
      "\n",
      "================================================================================\n",
      "DATA CLEANING\n",
      "================================================================================\n",
      "✓ Original dataset: 6600 images\n",
      "✓ Cleaned dataset: 6600 images\n",
      "✓ Removed: 0 images (missing files or invalid boxes)\n",
      "\n",
      "================================================================================\n",
      "DATASET SPLITTING\n",
      "================================================================================\n",
      "✓ Train: 5279 images\n",
      "✓ Val:   1321 images\n",
      "\n",
      "Processing train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5279/5279 [01:14<00:00, 71.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1321/1321 [00:17<00:00, 74.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ SUCCESS! Dataset is ready at: dataset/yolo_ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Load\n",
    "    raw_data = load_data(config.ANNOTATION_FILE)\n",
    "    \n",
    "    # 2. Clean (Cell 7 logic)\n",
    "    cleaned_data = clean_dataset(raw_data, config)\n",
    "    \n",
    "    # 3. Split (Cell 8 logic)\n",
    "    splits = split_dataset(cleaned_data, config)\n",
    "    \n",
    "    # 4. Process (Cell 9 logic)\n",
    "    for split in ['train', 'val']:\n",
    "        process_and_save_split(splits[split], split, config)\n",
    "        \n",
    "    print(\"\\n✓ SUCCESS! Dataset is ready at: dataset/yolo_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa6381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
