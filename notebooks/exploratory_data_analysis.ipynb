{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9129ea3",
   "metadata": {},
   "source": [
    "# Deep Learning for Tuberculosis Detection and Classification: A YOLO-v8 + Convolutional Block Attention Module Approach\n",
    "\n",
    "By: John Abuel\n",
    "\n",
    "### Overview of the TBX11K Dataset\n",
    "\n",
    "Source;\n",
    "Tuberculosis X-ray dataset contains 11200 X-ray images with corresponding bounding box annotations for tuberculosis (TB) areas, while the existing largest public TB datasets have much fewer X-ray images with corresponding image-level annotations. All images are with a size of 512x512. There are five main categories in this dataset: healthy, sick_but_non-tb, active_tb, latent_tb, and uncertain_tb. Also, the dataset includes the active_tb&latent_tb categorie. The authors split this dataset into train, val, and test sets, consisting of 6600, 1800, and 2800(3302) X-ray images, respectively. The proposed dataset enables the training of sophisticated detectors for high-quality computer-aided tuberculosis diagnosis (CTD). Authors reform the existing object detectors to adapt them to simultaneous image classification and TB area detection. These reformed detectors are trained and evaluated on the proposed TBX11K dataset and serve as the baselines for future research.\n",
    "\n",
    "\n",
    "\n",
    "As a serious infectious disease, tuberculosis (TB) is one of the major threats to human health worldwide, leading to millions of death every year. Although early diagnosis and treatment can greatly improve the chances of survival, it remains a major challenge, especially in developing countries. Computer-aided tuberculosis diagnosis (CTD) is a promising choice for TB diagnosis due to the great successes of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd01681",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbd91dde",
   "metadata": {},
   "source": [
    "## Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e666b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f27f3e",
   "metadata": {},
   "source": [
    "## Configuration for TBX11K preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6c3387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration loaded\n",
      "  Raw data: ../dataset/raw_data/TBX11K\n",
      "  Output: ../dataset/data/TBX11K\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration for TBX11K preprocessing\"\"\"\n",
    "    \n",
    "    # Raw data paths (download from TBX11K dataset)\n",
    "    RAW_DATA_ROOT = '../dataset/raw_data/TBX11K'\n",
    "    RAW_IMAGES = os.path.join(RAW_DATA_ROOT, 'imgs')\n",
    "    RAW_ANNOTATIONS = os.path.join(RAW_DATA_ROOT, 'annotations')\n",
    "    \n",
    "    # Processed data paths\n",
    "    PROCESSED_ROOT = '../dataset/data/TBX11K'\n",
    "    TRAIN_IMAGES = os.path.join(PROCESSED_ROOT, 'train', 'images')\n",
    "    TRAIN_LABELS = os.path.join(PROCESSED_ROOT, 'train', 'labels')\n",
    "    VAL_IMAGES = os.path.join(PROCESSED_ROOT, 'val', 'images')\n",
    "    VAL_LABELS = os.path.join(PROCESSED_ROOT, 'val', 'labels')\n",
    "    TEST_IMAGES = os.path.join(PROCESSED_ROOT, 'test', 'images')\n",
    "    TEST_LABELS = os.path.join(PROCESSED_ROOT, 'test', 'labels')\n",
    "    \n",
    "    # Classification data (for classifier training)\n",
    "    CLASSIFICATION_ROOT = '../dataset/data/classification'\n",
    "    \n",
    "    # Split ratios\n",
    "    TRAIN_RATIO = 0.7\n",
    "    VAL_RATIO = 0.15\n",
    "    TEST_RATIO = 0.15\n",
    "    \n",
    "    # Image processing\n",
    "    TARGET_SIZE = (640, 640)  # For YOLO\n",
    "    NORMALIZE = True\n",
    "    \n",
    "    # Quality control\n",
    "    MIN_IMAGE_SIZE = (224, 224)\n",
    "    MAX_IMAGE_SIZE = (4096, 4096)\n",
    "    MIN_BOX_AREA = 100  # pixels\n",
    "    \n",
    "config = Config()  \n",
    "\n",
    "# Create directories\n",
    "\n",
    "for path in [config.TRAIN_IMAGES, config.TRAIN_LABELS,\n",
    "             config.VAL_IMAGES, config.VAL_LABELS,\n",
    "             config.TEST_IMAGES, config.TEST_LABELS]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"âœ“ Configuration loaded\")\n",
    "print(f\"  Raw data: {config.RAW_DATA_ROOT}\")\n",
    "print(f\"  Output: {config.PROCESSED_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9316849",
   "metadata": {},
   "source": [
    "## Loading and Parsing TBX11K Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34b44214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading TBX11K annotations...\n",
      "Loaded 6600 images\n",
      "Categories: ['ActiveTuberculosis', 'ObsoletePulmonaryTuberculosis', 'PulmonaryTuberculosis']\n"
     ]
    }
   ],
   "source": [
    "def load_tbx11k_annotations(annotation_file):\n",
    "    \"\"\"\n",
    "    Load TBX11K annotations from JSON format\n",
    "    \n",
    "    TBX11K format:\n",
    "    {\n",
    "        \"images\": [...],\n",
    "        \"annotations\": [...],\n",
    "        \"categories\": [...]\n",
    "    }\n",
    "    \"\"\"\n",
    "    print(\"\\nLoading TBX11K annotations...\")\n",
    "    \n",
    "    with open(annotation_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Parse images\n",
    "    images = {}\n",
    "    for img in data['images']:\n",
    "        images[img['id']] = {\n",
    "            'file_name': img['file_name'],\n",
    "            'width': img.get('width', 0),\n",
    "            'height': img.get('height', 0),\n",
    "            'sex': img.get('sex', 'Unknown'),  # Often 'M' or 'F'\n",
    "            'age': img.get('age', None),       # Integer age\n",
    "            'global_category': img.get('syms', 'Unknown'), # Sometimes stored as 'syms' or implied\n",
    "            'annotations': []\n",
    "        }\n",
    "    \n",
    "    # Parse categories\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    \n",
    "    # Parse annotations\n",
    "    for ann in data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id in images:\n",
    "            images[img_id]['annotations'].append({\n",
    "                'bbox': ann['bbox'],  # [x, y, width, height]\n",
    "                'category_id': ann['category_id'],\n",
    "                'category_name': categories.get(ann['category_id'], 'unknown'),\n",
    "                'area': ann.get('area', 0)\n",
    "            })\n",
    "\n",
    "    for img_id, img_data in images.items():\n",
    "        if len(img_data['annotations']) > 0:\n",
    "            img_data['global_category'] = 'TB'\n",
    "        elif img_data['global_category'] == 'Unknown':\n",
    "             # Fallback if specific metadata isn't found\n",
    "            img_data['global_category'] = 'Non-TB (Healthy or Sick)'\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images\")\n",
    "    print(f\"Categories: {list(categories.values())}\")\n",
    "    \n",
    "    return images, categories\n",
    "\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..')) # Go up from notebooks/\n",
    "annotation_path = os.path.join(base_dir, 'dataset', 'raw_data', 'TBX11K', 'annotations', 'json', 'TBX11K_train.json')\n",
    "\n",
    "if os.path.exists(annotation_path):\n",
    "    images_data, categories = load_tbx11k_annotations(annotation_path)\n",
    "    # Now run your EDA function\n",
    "else:\n",
    "    print(f\"âš  Annotation file not found at: {annotation_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534428b",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis of TBX11K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c391ce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing images and pixel intensities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6600/6600 [00:05<00:00, 1190.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "      DATASET ANALYSIS REPORT      \n",
      "==================================================\n",
      "\n",
      "ðŸ“¸ IMAGE-LEVEL DISTRIBUTION\n",
      "Total Images: 6600\n",
      "  - With TB (Annotations): 599 (9.1%)\n",
      "  - No TB (Healthy/Sick):  6001 (90.9%)\n",
      "\n",
      "ðŸ·ï¸ ANNOTATION CLASS DISTRIBUTION (Active vs Latent)\n",
      "Total Boxes: 902\n",
      "  - ActiveTuberculosis            : 724 (80.3%)\n",
      "  - ObsoletePulmonaryTuberculosis : 178 (19.7%)\n",
      "\n",
      "ðŸ“¦ BOUNDING BOX GEOMETRY\n",
      "  - Overall Mean Area:      16151 pxÂ²\n",
      "  - Active TB Mean Area:    16870 pxÂ²\n",
      "  - Latent TB Mean Area:    13224 pxÂ²\n",
      "    (Latent boxes are 21.6% smaller on average)\n",
      "\n",
      "ðŸ’¡ PIXEL INTENSITY & CONTRAST (CBAM Justification)\n",
      "  - Avg Lesion Intensity:     121.2 (0-255)\n",
      "  - Avg Background Intensity: 132.7 (0-255)\n",
      "  - Mean Contrast Ratio:      0.920\n",
      "\n",
      "  âœ… CONCLUSION: Low contrast detected (< 1.15).\n",
      "     Lesions are visually subtle compared to the background.\n",
      "     This strictly justifies using CBAM attention to boost feature extraction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def perform_eda(images_data, config):\n",
    "    \"\"\"Comprehensive EDA including Pixel Intensity & Class-Specific Box Stats\"\"\"\n",
    "\n",
    "    stats = {\n",
    "        'num_images': len(images_data),\n",
    "        'num_with_annotations': 0,\n",
    "        'num_without_annotations': 0,\n",
    "        'total_boxes': 0,\n",
    "        'boxes_per_image': [],\n",
    "        # Box dimensions\n",
    "        'box_areas_active': [],\n",
    "        'box_areas_latent': [],\n",
    "        'box_areas_all': [],\n",
    "        # Pixel Intensity Stats\n",
    "        'lesion_intensity': [],\n",
    "        'background_intensity': [],\n",
    "        'contrast_ratios': [],\n",
    "        # Class Counts\n",
    "        'category_counts': defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    print(\"Analyzing images and pixel intensities...\")\n",
    "    \n",
    "    for img_id, img_info in tqdm(images_data.items(), desc=\"Processing\"):\n",
    "        img_path = os.path.join(config.RAW_IMAGES, img_info['file_name'])\n",
    "        \n",
    "        # Check file existence\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "            \n",
    "        annotations = img_info['annotations']\n",
    "        num_boxes = len(annotations)\n",
    "        stats['boxes_per_image'].append(num_boxes)\n",
    "        \n",
    "        # --- 1. Class & Box Analysis ---\n",
    "        if num_boxes > 0:\n",
    "            stats['num_with_annotations'] += 1\n",
    "            stats['total_boxes'] += num_boxes\n",
    "            \n",
    "            # Load image for pixel analysis (Grayscale is sufficient for intensity)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = None\n",
    "            if img is not None:\n",
    "                mask = np.zeros_like(img)\n",
    "\n",
    "            for ann in annotations:\n",
    "                cat_name = ann['category_name']\n",
    "                stats['category_counts'][cat_name] += 1\n",
    "                \n",
    "                # Box Geometry\n",
    "                x, y, w, h = map(int, ann['bbox'])\n",
    "                area = w * h\n",
    "                stats['box_areas_all'].append(area)\n",
    "                \n",
    "                # Class-specific areas (checking for partial string matches for safety)\n",
    "                if 'Active' in cat_name:\n",
    "                    stats['box_areas_active'].append(area)\n",
    "                elif 'Obsolete' in cat_name or 'Latent' in cat_name:\n",
    "                    stats['box_areas_latent'].append(area)\n",
    "                \n",
    "                # Prepare Mask\n",
    "                if img is not None:\n",
    "                    # Draw filled rectangle for the lesion\n",
    "                    cv2.rectangle(mask, (x, y), (x+w, y+h), 255, -1)\n",
    "            \n",
    "            # --- 2. Pixel Intensity Analysis ---\n",
    "            if img is not None:\n",
    "                # Pixels inside boxes (Lesions)\n",
    "                lesion_pix = img[mask == 255]\n",
    "                # Pixels outside boxes (Background/Healthy Lung)\n",
    "                bg_pix = img[mask == 0]\n",
    "                \n",
    "                if len(lesion_pix) > 0 and len(bg_pix) > 0:\n",
    "                    l_mean = np.mean(lesion_pix)\n",
    "                    b_mean = np.mean(bg_pix)\n",
    "                    stats['lesion_intensity'].append(l_mean)\n",
    "                    stats['background_intensity'].append(b_mean)\n",
    "                    # Avoid divide by zero\n",
    "                    stats['contrast_ratios'].append(l_mean / (b_mean + 1e-6))\n",
    "        else:\n",
    "            stats['num_without_annotations'] += 1\n",
    "\n",
    "    # --- REPORTING ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"      DATASET ANALYSIS REPORT      \")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 1. Global Class Distribution\n",
    "    print(f\"\\n IMAGE-LEVEL DISTRIBUTION\")\n",
    "    print(f\"Total Images: {stats['num_images']}\")\n",
    "    print(f\"  - With TB (Annotations): {stats['num_with_annotations']} ({stats['num_with_annotations']/stats['num_images']*100:.1f}%)\")\n",
    "    print(f\"  - No TB (Healthy/Sick):  {stats['num_without_annotations']} ({stats['num_without_annotations']/stats['num_images']*100:.1f}%)\")\n",
    "\n",
    "    # 2. Annotation Class Distribution\n",
    "    print(f\"\\n ANNOTATION CLASS DISTRIBUTION (Active vs Latent)\")\n",
    "    total_boxes = stats['total_boxes']\n",
    "    print(f\"Total Boxes: {total_boxes}\")\n",
    "    for cat, count in sorted(stats['category_counts'].items()):\n",
    "        ratio = (count / total_boxes) * 100 if total_boxes > 0 else 0\n",
    "        print(f\"  - {cat:<30}: {count} ({ratio:.1f}%)\")\n",
    "\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Perform EDA\n",
    "if images_data:\n",
    "    dataset_stats = perform_eda(images_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b8866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
